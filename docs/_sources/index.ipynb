{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1498847a-f284-4773-9e29-822a7be6aa60",
   "metadata": {},
   "source": [
    "# DSCI 542 Lab 2\n",
    "\n",
    "# Exercise 1\n",
    "\n",
    "The target audiences for this report are the prospective undergraduate students who have limited knowledge in the field of computer science and statistics and graduates who wish to change their profession to computing science. This report is aimed at giving new students a general picture about the payment of being a programmer in Canada. Students who have no clue about their future careers will be interested in this report that shows the most important factors or skills associated with their career prospects based on real data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac89e6a-333a-469e-bcb7-e0fd2e1e6cfc",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0b1165-66b6-4581-b18d-346251ec9beb",
   "metadata": {},
   "source": [
    "# Modeling programmers’ payments in Canada based on survey data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec25e436-d777-42f1-b89f-0530410581ae",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "For prospective university students and graduate students who wish to change their career to computing science, which factors are correlated to their future payment levels is the most frequent question in their mind. If they could get a sketch of their future career as being a programmer, they would be able to plan their study and career in a way much closer to the market demand. Here we built a model to predict the income of programmers in Canada by using a multi-linear regression model based on the following features: years of coding experience, programming languages used, education level, and role. After the hyperparameter tuning process, $R^2$ of the training data set increases from 0.67 to 0.72, and the model is also tested on the testing data set with $R^2 = 0.71$, which is consistent with the training result. We discovered that the programming languages mastered are the most important factors in our model, which means that students are better off learning a basket of programming languages such as Java, SQL, Bash, HTML. According to the model built, programmers who are skillful in these languages earn more. Besides, there are 3 points that we want to explore further in the future: to find other explanatory variables that might give us a better score, to include the United States in our model, to identify the best features that contribute to the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4af69e-ca21-4c5a-b683-0da4ea13ca90",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This project intends to build up a linear regression model to predict a programmer’s expected salary based on the survey data from Stack Overflow in the hope that students can get updated with the latest labor market. In a recent decade, there have been many huge leaps in the digital world ranging from computer software to mobile applications, from Google Alpha Go to Facebook Meta, from cash or card payment to e-wallet on smartphones. All these changes accelerate the shifts from one computing skill to the other. Accordingly, technicians’ salaries change with the changing preference of the tech companies. For instance, with customer profiling getting popular, technicians who skill in SQL and Java are more likely to be well-paid. The rapid changes in the labor market have made rookies hard to follow. Students may also come up with questions such as whether programmers who focus on one programming language or who are skillful in a basket of programming languages are paid more in the market. Another popular question is what the payment level can reach after years in this profession. These questions can be categorized into inference and prediction. Finding factors that are associated with the payment level are inference, and using data to estimate the payment level is prediction. This paper mainly focuses on the prediction part, and explanatory variables used are referred from the salary calculator of Stack Overflow.\n",
    "\n",
    "There are mainly 3 simple supervised learning methods: decision tree, k-nearest neighbor, and linear regression. Decision trees create a non-parametric model to predict the value of a target variable by learning simple decision rules inferred from the data feature. The learning results can be regarded as a piecewise constant approximation {cite:p}`scikit-learn`. Neighbor-based regression is a type of instance-based learning which does not attempt to construct a general internal model, but simply stores instances of the training data and finds the most similar case as the prediction result {cite:p}`scikit-learn`. Linear regression is a linear approach for modeling the relationship between a continuous response and one or more explanatory variables, which can be expressed in the form:\n",
    "\n",
    "$$ \n",
    "    y_{salary} = w^T X + b\n",
    "$$\n",
    "\n",
    "The most significant difference among them is that the linear regression model can provide a continuous prediction result, whereas decision tree and k-nearest neighbor methods can only provide a discrete result. Moreover, both decision tree and k-nearest neighbor models are non-parametric, but linear regression models are parametric, which have stronger explaining power in terms of the prediction result and the relationship estimated. Therefore, the linear regression model was hired in this project.\n",
    "\n",
    "Based on the previous work done by Stack Overflow, factors (education level, location, the language used, job type) used in the [salary calculator](https://stackoverflow.com/jobs/salary) are employed directly in the following research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e86a0c-f700-448e-920c-5b6ab1e43674",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "### Data preprocessing\n",
    "\n",
    "The data set used in this project is from the [Stack Overflow Annual Developer Survey 2019](https://insights.stackoverflow.com/survey), which is conducted annually. The survey data set has nearly 80,000 responses, collecting respondents’ data from following dimensions in {numref}`survey_data_dimensions`:\n",
    "\n",
    "```{table} Summary of data collected in Stack Overflow Annual Developer Survey, 2019\n",
    ":name: survey_data_dimensions\n",
    "\n",
    "| Category | Features |\n",
    "|---|---|\n",
    "|developer profile|geography, developer roles, years since learning to code, education, undergraduate major, race and ethnicity, gender, age, etc.|\n",
    "|technology|programming or markup languages, databases, platforms, developers' primary operating systems, etc.|\n",
    "|work|employment status, company type, company size, career values, hours worked per week, etc.|\n",
    "```\n",
    "There are several useful features that could be extracted from this survey such as education level, location, the language used, job type, all of which are potentially associated with annual compensation. As mentioned before, this report is based on the work previously done by the salary calculator of Stack Overflow. Hence, these features are employed in the linear regression model: years of coding experience, programming languages used, education level, and role {cite:p}`stack_overflow_survey`.\n",
    "\n",
    "Thanks to Stack Overflow, the raw data can be directly downloaded in the format of `csv` and used for free. There is a sufficient amount of data in the file (more than 80,000 rows of data), so missing values were filtered out and outliers which are defined as data points lying out of 5 standard deviations were also removed in the data preprocessing step. Additionally, the data within Canada were used as the project is to predict the salary of programmers in Canada.\n",
    "\n",
    "Next, the data set was split into the training and test data sets with a ratio of 8:2 by using the function, `sklearn.model_selection.train_test_split`.\n",
    "\n",
    "### Exploratory Data Analysis\n",
    "\n",
    "After performing EDA on the training data set,  there are several points worth mentioning. The distribution of the response variable, salary, is positively skewed with a fat tail, as shown in Fig. 1 {cite:p}`vanderplas2018altair`. This attribute is undesirable, which makes the model less robust. So, extremely high salaries that are out of 5 standard deviations were defined as outliers which were removed in the preprocessing step.<br>\n",
    "\n",
    "```{figure} ../results/salary_density_plot.png\n",
    "---\n",
    "height: 400px\n",
    "name: salary_density\n",
    "---\n",
    "Density plot of annual compensation(USD): The distribution of annual compensation is right skewed with extremely large value as well as extremely small value.\n",
    "```\n",
    "\n",
    "Among all the features investigated, it can be found that the salary is strongly correlated to the number of professional coding years. Fig.2 clearly shows that there is a linear relationship between the number of professional coding years and the salary. Figure.3 displays both effects of professional coding years and languages mastered on the salary.\n",
    "\n",
    "```{figure} ../results/code_years_plot.png\n",
    "---\n",
    "height: 400px\n",
    "name: code_years_plot\n",
    "---\n",
    "Coding year vs. annual compensation(USD): Number of coding years is strongly correlated to compensation, but becomes widely spread when the coding years are greater than 20.\n",
    "```\n",
    "\n",
    "```{figure} ../results/language_codeyears_plot.png\n",
    "---\n",
    "height: 150px\n",
    "name: language_code_years_plot\n",
    "---\n",
    "Both effects of languages mastered and coding years on annual compensation: The more languages mastered and the more years in professional experience, the higher compensation expected.\n",
    "```\n",
    "\n",
    "Figures below present how other 3 features we selected have significant effects on the income level.\n",
    "```{figure} ../results/edu_plot.png\n",
    "---\n",
    "height: 150px\n",
    "name: edu_plot\n",
    "---\n",
    "Education level vs. annual compensation(USD): Education levels are positively related to compensation.\n",
    "```\n",
    "```{figure} ../results/language_plot.png\n",
    "---\n",
    "height: 150px\n",
    "name: lang_plot\n",
    "---\n",
    "Programming languages vs. annual compensation(USD): Programming languages is associated with compensation. The more programming languages mastered, the higher compensation.\n",
    "```\n",
    "```{figure} ../results/role_plot.png\n",
    "---\n",
    "height: 150px\n",
    "name: role_plot\n",
    "---\n",
    "Roles vs. annual compensation(USD): Roles are related to compensation. Mobile and back-end developers have greater compensation.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052da171-4370-4955-80a8-a684a9f64902",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "In light of EDA and previous work of Stack Overflow, 4 features are extracted that are duration for being a profession, education level, programming language worked with and job position. Then, the regression equation can be obtained:<br>\n",
    "\n",
    "$$ \n",
    "    y_{salary} = w^T X + b\n",
    "$$\n",
    "\n",
    "*where w is the weight vector, X is the feature vector, b is the error term, $y_{salary}$ is predicted variable.* <br>\n",
    "\n",
    "Ridge model is chosen in this case, which can help reduce over-fitting problems. Ridge solves a regression model where the loss function is the linear least squares function and regularization is given by the L2-norm. \n",
    "\n",
    "$$\n",
    "    loss\\ function = ||y - w^T X||^2_2 + alpha * ||w||^2_2\n",
    "$$\n",
    "\n",
    "*where alpha is regularization strength to reduces the variance of the estimates. Larger values specify stronger regularization.* <br>\n",
    "\n",
    "Within the training data set, randomized hyperparameter searching was carried out based on the scoring matrix, $R^2$. Then, the model with the best performed parameter was used to make prediction on the test data set. In this case, no feature engineering work was performed in this report, meaning that the number of regressors is fixed. Hence, $R^2$ was used to evaluate the model instead of $R_{adjusted}^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e5d211-a7e2-473b-8014-ea6a9248fac1",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "As mentioned previously, Ridge model is selected in order to avoid conditioning problems and large estimator coefficients. Firstly, hypeparameterization of alpha is carried out. The hyperparameter tuning result shows that the model is at the best performance when alpha = 0.091 with a training $R^2$  of 0.725 as shown in the figure below.\n",
    "\n",
    "```{figure} ../results/alpha-tuning.png\n",
    "---\n",
    "height: 400px\n",
    "name: alpha-tuning\n",
    "---\n",
    "Hyperparameter searching: the model is well trained when the hyperparameter, alpha, equals to 0.091. With a greater alpha, the model is under-fitted, whereas the model is over-fitted if alpha is getting smaller than 0.091.\n",
    "```\n",
    "Applying the fitted model to the test data set, we get a testing $R^2$ of 0.718.<br>\n",
    "\n",
    "After identifying the most important features, we built multiple linear regression models with the annual salary as our response variable and the following predictors: years of coding experience, programming languages used, education level, and role. Since our target is a continuous variable, regression made sense here.<br>\n",
    "\n",
    "We carried out hyper-parameter tuning via cross validation with `RandomizedSearchCV`. This allowed us to find optimal parameters which improved our validation score from 67% to 72%. We tested the final model on our test data (20% of the survey data) and the model performed well on the test data with an accuracy of 71%. As you can see in Fig 8, the model is slightly under predicting or over-predicting, but the fit seems to be good. This is a decent score that indicates that our model generalizes enough and should perform well on unseen examples.\n",
    "\n",
    "```{figure} ../results/test_data_result.png\n",
    "---\n",
    "height: 400px\n",
    "name: test_data_result\n",
    "---\n",
    "Predicted salary VS. observed salary: the fitted model can fairly predict the salary.\n",
    "```\n",
    "\n",
    "Furthermore, by ranking the values of coefficient of regressors in a descending order, it can be found that the programming languages mastered play a more pivotal role as shown in {numref}`coef_tb`.\n",
    "\n",
    "```{table} Top 5 features positively related to the salary\n",
    ":name: coef_tb\n",
    "| Feature | Coefficient |\n",
    "|---|---|\n",
    "|Language worked with Java,R,SQL|296106|\n",
    "|Language worked with Bash,C++,Go,JavaScript,Python,Rust,Scala|219395|\n",
    "|Language worked with Bash, C, Dart, Go,HTML,Java,JavaScript,Python,Ruby,SQL|219145|\n",
    "|Language worked with Bash,HTML,JavaScript,Python,R,SQL|178592|\n",
    "|Language worked with C#,Java,JavaScript,Python,SQL,Swift|150506|\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc8e516-2848-4f7d-8b62-446f04bc9942",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In brief, our linear regression model uses 4 features (that are years of coding experience, programming languages used, education level, and role) to predict salary. It predicts with a $R^2$ score of 0.725 on the training data set, which also performs fairly well on the test data set. Meanwhile, our work has shown that the salary is closely related to these 4 features. \n",
    "\n",
    "However, there are still limitations in our work. We just used a small part of data from the survey and we are inclined to explore more features to boost the robustness and accuracy of our prediction results. Hence, in the future, we plan to do two important changes; exploring other explanatory variables that might give us a better score, and including the United States in our model. In order to identify the best features that contribute to the prediction, we will include all the sensible columns in the original survey, and perform model and feature selection. We hope that this will help us discover more features that are important for the annual compensation prediction of tech employees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af84d0d-f49c-4a21-8127-f159587645f4",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "```{bibliography}\n",
    ":style: unsrtalpha\n",
    ":all:\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e145e30c-a561-4bb2-9fdc-7c96a0f30639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
